---

# Wake Word Detection ğŸ”Š

An **end-to-end deep learning pipeline** for **custom wake word detection**, powered by **TensorFlow** and **ElevenLabs TTS**.

This project covers the full workflow â€” from **audio generation and preprocessing** to **GRU-based model training and evaluation**.

---

## âš™ï¸ Features

âœ… Generate *activate* and *negative* samples using **ElevenLabs TTS**
âœ… Mix with *background noise* for realistic audio data
âœ… Automatic creation of *training* and *dev* datasets
âœ… Train a **GRU (Gated Recurrent Unit)** based deep learning model
âœ… Evaluate, test, and visualize model predictions

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/Madhusanka-slc/wake-word-detection.git
cd wake-word-detection
```

---

## ğŸ Environment Setup

### Create and Activate Virtual Environment

```bash
# Create environment
python -m venv wakeword-env

# Activate (Windows)
wakeword-env\Scripts\activate
# or (macOS/Linux)
source wakeword-env/bin/activate
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

âœ… Requires **Python 3.8+**

---

## ğŸ”‘ Setup API Key

Copy the example `.env` file:

```bash
cp .env.example .env
```

Add your **ElevenLabs API key**:

```env
ELEVENLABS_API_KEY=your_api_key_here
```

ğŸ‘‰ Get your key from [ElevenLabs â†’ Profile Settings](https://elevenlabs.io/)

---

## ğŸ§ Add Background Audio

Place your 10-second background clips here:

```
data/raw/backgrounds/
```

Examples: ambient noise, music, office chatter, etc.
Formats: `.wav`, `.mp3`, `.m4a`

> You need at least **2â€“5 clips** for the system to work properly.

---

## ğŸ§  Full Pipeline (Run in Order)

Open Jupyter and execute the following notebooks:

1. **1_data_downloading.ipynb** â†’ Download or create *activate* and *negative* audio samples
2. **2_data_creation.ipynb** â†’ Generate labeled *training* and *dev* datasets
3. **3_training.ipynb** â†’ Build and train the **GRU-based wake word detection model**
4. **4_test_model.ipynb** â†’ Test and visualize model performance

```bash
jupyter notebook
```

---

## ğŸ§© Utility Script

**`td_utils.py`** â€“ Helper functions for:

* Audio preprocessing and normalization
* Spectrogram generation
* Label creation for training sequences
* Visualization and analysis utilities

---

## ğŸ§  Model Architecture

The wake word detection model is built using:

* **Conv1D layers** â€“ for low-level temporal feature extraction
* **Bidirectional GRU layers** â€“ for sequential context understanding
* **Dense + Sigmoid output** â€“ for frame-level wake word prediction

---

## ğŸ“‚ Project Structure

```
wake-word-detection/
â”œâ”€â”€ scripts/                    
â”‚   â”œâ”€â”€ 1_data_downloading.ipynb
â”‚   â”œâ”€â”€ 2_data_creation.ipynb
â”‚   â”œâ”€â”€ 3_training.ipynb
â”‚   â””â”€â”€ 4_test_model.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ backgrounds/        
â”‚   â””â”€â”€ processed/              
â”œâ”€â”€ models/                     # Saved GRU models
â”œâ”€â”€ audio/sample/               # Test samples
â”œâ”€â”€ td_utils.py                 # Helper utilities
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env                        # API key file
```

---

## ğŸ§° Requirements

* Python 3.8+
* TensorFlow
* ElevenLabs API Key
* Jupyter Notebook
* Background audio (10s clips)

---

## ğŸ“œ License

MIT License

Made with â¤ï¸ by [**Madhusanka**](https://github.com/Madhusanka-slc)

---